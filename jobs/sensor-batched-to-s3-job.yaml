# Job: IoT Sensor File to S3 (Batched)
# Reads sensor JSONL, enriches, batches, uploads to S3 with date partitioning
#
# Usage:
#   expanso-cli job deploy jobs/sensor-batched-to-s3-job.yaml
#
# Prerequisites:
#   Run sensor-gen binary on edge node to generate data:
#   ./sensor-gen -d 60s -o /data/sensors/input.jsonl
#
# Required Configuration (set on edge nodes):
#   - S3_BUCKET: Target S3 bucket
#
# Optional Configuration:
#   - INPUT_FILE: Path to sensor JSONL (default: /data/sensors/input.jsonl)
#   - AWS_REGION: AWS region (default: us-east-1)
#   - S3_PREFIX: Object key prefix (default: sensor-data/)
#   - BATCH_SIZE: Records per batch (default: 1000)
#   - BATCH_PERIOD: Max batch time (default: 60s)
#   - EDGE_NODE_ID: Node identifier (default: hostname)

name: sensor-batched-to-s3
type: pipeline

selector:
  match_labels:
    role: edge-processor
    output: s3

config:
  input:
    file:
      paths:
        - "${INPUT_FILE:/data/sensors/input.jsonl}"
      scanner:
        lines: {}

  pipeline:
    processors:
      # Enrich each record
      - mapping: |
          root = this
          root.lineage = {
            "edge_node": env("EDGE_NODE_ID").or(env("HOSTNAME")).or("unknown"),
            "pipeline": "sensor-batched-to-s3",
            "ingested_at": now().ts_format("2006-01-02T15:04:05.000Z")
          }

          let is_anomaly = this.type == "pressure" && this.value > 1500
          let is_anomaly = $is_anomaly || (this.type == "temperature" && (this.value > 180 || this.value < -20))
          let is_anomaly = $is_anomaly || (this.type == "flow_rate" && this.value > 50000)
          let is_anomaly = $is_anomaly || this.quality_score < 0.8

          root.data_quality = {
            "is_anomaly": $is_anomaly,
            "validated": true
          }

  output:
    aws_s3:
      bucket: "${S3_BUCKET}"
      path: '${S3_PREFIX:sensor-data/}${!timestamp_unix:2006}/${!timestamp_unix:01}/${!timestamp_unix:02}/${!env("HOSTNAME").or("edge")}_${!timestamp_unix_nano()}.json'
      region: "${AWS_REGION:us-east-1}"
      content_type: "application/json"
    batching:
      count: ${BATCH_SIZE:1000}
      period: "${BATCH_PERIOD:60s}"
      processors:
        - archive:
            format: json_array
        - mapping: |
            let records = this
            let count = $records.length()
            let anomaly_count = $records.filter(r -> r.data_quality.is_anomaly == true).length()

            root = {
              "batch_meta": {
                "record_count": $count,
                "anomaly_count": $anomaly_count,
                "anomaly_rate_pct": if $count > 0 { (($anomaly_count / $count) * 100).round() } else { 0 },
                "batch_time": now().ts_format("2006-01-02T15:04:05.000Z"),
                "edge_node": env("EDGE_NODE_ID").or(env("HOSTNAME")).or("unknown")
              },
              "records": $records
            }
